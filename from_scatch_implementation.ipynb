{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 1: Imports and Configuration\n",
    "\n",
    "This cell sets up the Python environment and defines constants for the facial recognition model.\n",
    "\n",
    "- **Imports**: Libraries for numerical computation (`numpy`), MLX for model building and training (`mlx.core`, `mlx.nn`, `mlx.optimizers`), dataset loading (`sklearn.datasets`), and image processing (`PIL`, `cv2`).\n",
    "- **Constants**:\n",
    "  - Image size: $IMG\\_SIZE = (224, 224)$, the target dimensions for input images.\n",
    "  - Number of triplets: $NUM\\_TRIPLETS = 1000$, the number of training examples for triplet loss.\n",
    "  - Epochs: $EPOCHS = 10$, iterations over the dataset.\n",
    "  - Learning rate: $LEARNING\\_RATE = 0.001$, step size for gradient descent, where the update rule is $w_{t+1} = w_t - \\eta \\nabla L(w_t)$ with $\\eta = 0.001$.\n",
    "  - Margin: $MARGIN = 0.2$, used in triplet loss to enforce separation, defined as $L = \\max(0, d(a, p) - d(a, n) + m)$ where $m = 0.2$.\n",
    "  - Threshold: $THRESHOLD = 0.6$, for recognition, where a distance $d(e, e_k) < \\theta$ identifies a match, with $\\theta = 0.6$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration set. Using sklearn's LFW dataset.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import mlx.core as mx\n",
    "import mlx.nn as nn\n",
    "import mlx.optimizers as optim\n",
    "import random\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "# Configuration\n",
    "IMG_SIZE = (224, 224)\n",
    "NUM_TRIPLETS = 1000\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 0.001\n",
    "MARGIN = 0.2\n",
    "THRESHOLD = 0.6\n",
    "\n",
    "print(\"Configuration set. Using sklearn's LFW dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample face shape: (224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "def preprocess_image(img):\n",
    "    \"\"\"Resize and normalize LFW image.\"\"\"\n",
    "    # img is a numpy array (H, W) or (H, W, C) from sklearn\n",
    "    if len(img.shape) == 2:  # Grayscale to RGB\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "    face = cv2.resize(img, IMG_SIZE)\n",
    "    return face / 255.0  # Normalize to [0, 1]\n",
    "\n",
    "# Test preprocessing\n",
    "lfw_data = fetch_lfw_people(min_faces_per_person=2, resize=0.4, download_if_missing=True)\n",
    "sample_img = lfw_data.images[0]  # Get first image (70x50 grayscale by default)\n",
    "sample_face = preprocess_image(sample_img)\n",
    "print(\"Sample face shape:\", sample_face.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1680 people with images.\n"
     ]
    }
   ],
   "source": [
    "def load_dataset():\n",
    "    \"\"\"Load LFW from sklearn and group by identity.\"\"\"\n",
    "    lfw_data = fetch_lfw_people(min_faces_per_person=2, resize=0.4, download_if_missing=True)\n",
    "    image_dict = {}\n",
    "    \n",
    "    for img, target in zip(lfw_data.images, lfw_data.target):\n",
    "        label = str(target)  # Use target ID as string key\n",
    "        face = preprocess_image(img)\n",
    "        if label not in image_dict:\n",
    "            image_dict[label] = []\n",
    "        image_dict[label].append(face)\n",
    "    \n",
    "    # Filter already done by min_faces_per_person, but confirm\n",
    "    image_dict = {k: v for k, v in image_dict.items() if len(v) > 1}\n",
    "    print(f\"Loaded {len(image_dict)} people with images.\")\n",
    "    return image_dict\n",
    "\n",
    "# Load the dataset\n",
    "image_dict = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 1000 triplets.\n"
     ]
    }
   ],
   "source": [
    "def generate_triplets(image_dict, num_triplets=NUM_TRIPLETS):\n",
    "    \"\"\"Generate (anchor, positive, negative) triplets.\"\"\"\n",
    "    triplets = []\n",
    "    person_names = list(image_dict.keys())\n",
    "    \n",
    "    for _ in range(num_triplets):\n",
    "        anchor_person = random.choice(person_names)\n",
    "        anchor, positive = random.sample(image_dict[anchor_person], 2)\n",
    "        negative_person = random.choice([p for p in person_names if p != anchor_person])\n",
    "        negative = random.choice(image_dict[negative_person])\n",
    "        triplets.append((anchor, positive, negative))\n",
    "    \n",
    "    return triplets\n",
    "\n",
    "def to_mlx_arrays(triplets):\n",
    "    \"\"\"Convert triplets to MLX arrays with batch dimension.\"\"\"\n",
    "    return [(mx.array(a[None, ...]), mx.array(p[None, ...]), mx.array(n[None, ...]))\n",
    "            for a, p, n in triplets]\n",
    "\n",
    "# Generate and convert triplets\n",
    "triplets = generate_triplets(image_dict)\n",
    "mlx_triplets = to_mlx_arrays(triplets)\n",
    "print(f\"Generated {len(triplets)} triplets.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n"
     ]
    }
   ],
   "source": [
    "class FaceCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1, 1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, 1, 1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc = nn.Linear(128 * 28 * 28, 128)  # 128D embedding\n",
    "\n",
    "    def __call__(self, x):\n",
    "        x = self.pool(nn.relu(self.conv1(x)))\n",
    "        x = self.pool(nn.relu(self.conv2(x)))\n",
    "        x = self.pool(nn.relu(self.conv3(x)))\n",
    "        x = x.reshape(x.shape[0], -1)  # Flatten\n",
    "        x = self.fc(x)\n",
    "        return x / mx.sqrt(mx.sum(x * x, axis=-1, keepdims=True))  # L2 normalize\n",
    "\n",
    "# Initialize model\n",
    "model = FaceCNN()\n",
    "print(\"Model initialized.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training functions defined.\n"
     ]
    }
   ],
   "source": [
    "def triplet_loss(anchor, positive, negative, margin=MARGIN):\n",
    "    \"\"\"Compute triplet loss.\"\"\"\n",
    "    pos_dist = mx.sum(mx.square(anchor - positive), axis=-1)\n",
    "    neg_dist = mx.sum(mx.square(anchor - negative), axis=-1)\n",
    "    return mx.mean(mx.maximum(pos_dist - neg_dist + margin, 0))\n",
    "\n",
    "def train_model(model, triplets, epochs=EPOCHS, learning_rate=LEARNING_RATE):\n",
    "    \"\"\"Train the model with triplet loss.\"\"\"\n",
    "    optimizer = optim.Adam(learning_rate=learning_rate)\n",
    "\n",
    "    def compute_loss(params, inputs):\n",
    "        \"\"\"Compute loss given model parameters and triplet inputs.\"\"\"\n",
    "        anchor, positive, negative = inputs\n",
    "        # Update model parameters\n",
    "        model.update(params)\n",
    "        anchor_emb = model(anchor)\n",
    "        pos_emb = model(positive)\n",
    "        neg_emb = model(negative)\n",
    "        return triplet_loss(anchor_emb, pos_emb, neg_emb)\n",
    "\n",
    "    # Get initial model parameters\n",
    "    params = model.parameters()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        random.shuffle(triplets)\n",
    "        total_loss = 0\n",
    "        for anchor, positive, negative in triplets:\n",
    "            # Compute value and gradients with respect to model parameters\n",
    "            loss, grads = mx.value_and_grad(compute_loss)(params, (anchor, positive, negative))\n",
    "            optimizer.update(model, grads)\n",
    "            mx.eval(model.parameters(), optimizer.state)\n",
    "            params = model.parameters()  # Update params after optimization step\n",
    "            total_loss += loss.item()\n",
    "        avg_loss = total_loss / len(triplets)\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {avg_loss:.4f}\")\n",
    "\n",
    "print(\"Training functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting training...\")\n",
    "train_model(model, mlx_triplets)\n",
    "print(\"Training completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference functions defined.\n"
     ]
    }
   ],
   "source": [
    "def get_embedding(model, image_path):\n",
    "    \"\"\"Generate embedding for an image.\"\"\"\n",
    "    face = preprocess_image(image_path)\n",
    "    if face is not None:\n",
    "        face = mx.array(face[None, ...])\n",
    "        return model(face).squeeze()\n",
    "    return None\n",
    "\n",
    "def build_database(model, image_dict, max_images_per_person=5):\n",
    "    \"\"\"Build a database of embeddings for known people.\"\"\"\n",
    "    database = {}\n",
    "    for person, images in image_dict.items():\n",
    "        embeddings = [get_embedding(model, os.path.join(DATASET_PATH, person, img_file))\n",
    "                      for img_file in os.listdir(os.path.join(DATASET_PATH, person))[:max_images_per_person]\n",
    "                      if get_embedding(model, os.path.join(DATASET_PATH, person, img_file)) is not None]\n",
    "        if embeddings:\n",
    "            database[person] = mx.mean(mx.stack(embeddings), axis=0)\n",
    "    return database\n",
    "\n",
    "def recognize_face(model, image_path, database, threshold=THRESHOLD):\n",
    "    \"\"\"Recognize a face from an image.\"\"\"\n",
    "    embedding = get_embedding(model, image_path)\n",
    "    if embedding is None:\n",
    "        return \"No face detected\"\n",
    "    distances = {name: mx.sum(mx.square(embedding - emb)).item() for name, emb in database.items()}\n",
    "    closest = min(distances, key=distances.get)\n",
    "    return closest if distances[closest] < threshold else \"Unknown\"\n",
    "\n",
    "print(\"Inference functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building database...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'image_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Build database\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBuilding database...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m database = build_database(model, \u001b[43mimage_dict\u001b[49m)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Test recognition\u001b[39;00m\n\u001b[32m      6\u001b[39m test_image_path = \u001b[33m\"\u001b[39m\u001b[33mpath_to_test_image.jpg\u001b[39m\u001b[33m\"\u001b[39m  \u001b[38;5;66;03m# Replace with a real image path\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'image_dict' is not defined"
     ]
    }
   ],
   "source": [
    "# Build database\n",
    "print(\"Building database...\")\n",
    "database = build_database(model, image_dict)\n",
    "\n",
    "# Test recognition\n",
    "test_image_path = \"path_to_test_image.jpg\"  # Replace with a real image path\n",
    "result = recognize_face(model, test_image_path, database)\n",
    "print(f\"Recognized as: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLX",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
